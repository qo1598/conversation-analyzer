'use client'

import { useState, useRef, useEffect } from 'react'

export default function AudioRecorder({ onRecordingComplete, onError, onAnalysisStart, sessionId }) {
  const [isRecording, setIsRecording] = useState(false)
  const [isPaused, setIsPaused] = useState(false)
  const [duration, setDuration] = useState(0)
  const [audioBlob, setAudioBlob] = useState(null)
  const [audioUrl, setAudioUrl] = useState(null)
  const [isUploading, setIsUploading] = useState(false)
  
  const mediaRecorderRef = useRef(null)
  const streamRef = useRef(null)
  const chunksRef = useRef([])
  const intervalRef = useRef(null)

  useEffect(() => {
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop())
      }
      if (intervalRef.current) {
        clearInterval(intervalRef.current)
      }
    }
  }, [])

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      })
      
      streamRef.current = stream
      chunksRef.current = []
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      
      mediaRecorderRef.current = mediaRecorder

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm' })
        setAudioBlob(blob)
        setAudioUrl(URL.createObjectURL(blob))
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop())
        }
      }

      mediaRecorder.start()
      setIsRecording(true)
      setDuration(0)
      
      // ë…¹ìŒ ì‹œê°„ ì¹´ìš´í„° ì‹œì‘
      intervalRef.current = setInterval(() => {
        setDuration(prev => prev + 1)
      }, 1000)

    } catch (err) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', err)
      onError('ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
    }
  }

  const pauseRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.pause()
      setIsPaused(true)
      clearInterval(intervalRef.current)
    }
  }

  const resumeRecording = () => {
    if (mediaRecorderRef.current && isPaused) {
      mediaRecorderRef.current.resume()
      setIsPaused(false)
      
      // ì¹´ìš´í„° ì¬ì‹œì‘
      intervalRef.current = setInterval(() => {
        setDuration(prev => prev + 1)
      }, 1000)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
      setIsPaused(false)
      clearInterval(intervalRef.current)
    }
  }

  const uploadRecording = async () => {
    if (!audioBlob) return

    setIsUploading(true)
    
    // ë¶„ì„ ì‹œì‘ ì½œë°± í˜¸ì¶œ
    if (onAnalysisStart) {
      onAnalysisStart()
    }
    
    try {
      const formData = new FormData()
      formData.append('audio', audioBlob, 'recording.webm')
      
      const response = await fetch('/api/analyze', {
        method: 'POST',
        body: formData
      })

      if (!response.ok) {
        throw new Error('ì—…ë¡œë“œ ì‹¤íŒ¨')
      }

      const result = await response.json()
      
      // ë¶„ì„ ê²°ê³¼ì™€ í•¨ê»˜ audioBlobë„ ì „ë‹¬
      onRecordingComplete({
        ...result,
        audioBlob: audioBlob,
        audioFile: new File([audioBlob], 'recording.webm', { type: 'audio/webm' })
      })
      
      // ë…¹ìŒ ë°ì´í„° ì´ˆê¸°í™”
      resetRecording()
      
    } catch (err) {
      console.error('ì—…ë¡œë“œ ì˜¤ë¥˜:', err)
      onError('ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    } finally {
      setIsUploading(false)
    }
  }

  const resetRecording = () => {
    setAudioBlob(null)
    setAudioUrl(null)
    setDuration(0)
    chunksRef.current = []
  }

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="bg-white border border-gray-200 rounded-xl p-6 shadow-sm">
      <h3 className="text-lg font-semibold mb-4 text-center">ì‹¤ì‹œê°„ ë…¹ìŒ</h3>
      
      {/* ë…¹ìŒ ì‹œê°„ í‘œì‹œ */}
      <div className="text-center mb-6">
        <div className="text-2xl font-mono font-bold text-gray-800">
          {formatTime(duration)}
        </div>
        <div className="text-sm text-gray-500 mt-1">
          {isRecording && !isPaused && 'ë…¹ìŒ ì¤‘...'}
          {isPaused && 'ì¼ì‹œì •ì§€'}
          {!isRecording && duration > 0 && 'ë…¹ìŒ ì™„ë£Œ'}
          {!isRecording && duration === 0 && 'ë…¹ìŒ ì¤€ë¹„'}
        </div>
      </div>

      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <div className="flex justify-center items-center space-x-3 mb-6">
        {!isRecording && duration === 0 && (
          <button
            onClick={startRecording}
            className="w-12 h-12 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center transition-colors shadow-md"
          >
            ğŸ¤
          </button>
        )}

        {isRecording && !isPaused && (
          <>
            <button
              onClick={pauseRecording}
              className="w-10 h-10 bg-yellow-500 hover:bg-yellow-600 text-white rounded-full flex items-center justify-center transition-colors"
            >
              â¸ï¸
            </button>
            <button
              onClick={stopRecording}
              className="w-12 h-12 bg-gray-600 hover:bg-gray-700 text-white rounded-full flex items-center justify-center transition-colors shadow-md"
            >
              â¹ï¸
            </button>
          </>
        )}

        {isPaused && (
          <>
            <button
              onClick={resumeRecording}
              className="w-10 h-10 bg-green-500 hover:bg-green-600 text-white rounded-full flex items-center justify-center transition-colors"
            >
              â–¶ï¸
            </button>
            <button
              onClick={stopRecording}
              className="w-12 h-12 bg-gray-600 hover:bg-gray-700 text-white rounded-full flex items-center justify-center transition-colors shadow-md"
            >
              â¹ï¸
            </button>
          </>
        )}
      </div>

      {/* ë…¹ìŒ ì™„ë£Œ í›„ ë¯¸ë¦¬ë³´ê¸° ë° ì—…ë¡œë“œ */}
      {audioUrl && !isRecording && (
        <div className="space-y-4">
          <div className="bg-gray-50 rounded-lg p-4">
            <h4 className="text-sm font-medium text-gray-700 mb-2">ë…¹ìŒ ë¯¸ë¦¬ë³´ê¸°</h4>
            <audio controls className="w-full" src={audioUrl}>
              ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ ì¬ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            </audio>
          </div>
          
          <div className="flex space-x-3">
            <button
              onClick={resetRecording}
              className="flex-1 py-2 px-4 border border-gray-300 text-gray-700 rounded-lg hover:bg-gray-50 transition-colors"
            >
              ë‹¤ì‹œ ë…¹ìŒ
            </button>
            <button
              onClick={uploadRecording}
              disabled={isUploading}
              className="flex-1 py-2 px-4 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors disabled:bg-gray-400 disabled:cursor-not-allowed"
            >
              {isUploading ? 'ì—…ë¡œë“œ ì¤‘...' : 'ì—…ë¡œë“œ'}
            </button>
          </div>
        </div>
      )}

      {/* ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì•ˆë‚´ */}
      <div className="mt-4 text-xs text-gray-500 text-center">
        <p>Chrome, Firefox, Safari ë“± ìµœì‹  ë¸Œë¼ìš°ì €ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
      </div>
    </div>
  )
} 